{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Question 2: Digit Classifier using Linear Regression\n",
    "##### with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Section 0: Data preparation & function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Import relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "# Non-interactive plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "# Interactive plotting\n",
    "from plotly import tools\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from plotly.offline import download_plotlyjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Configure environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "np.random.seed(521)\n",
    "\n",
    "# Defines Global Variable\n",
    "GRAPH_EXISTS = False\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Activate Plotly Offline for Jupyter\n",
    "pyo.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Load Tiny MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with np.load (\"tinymnist.npz\") as data:\n",
    "    trainData, trainTarget = data [\"x\"], data[\"y\"]\n",
    "    validData, validTarget = data [\"x_valid\"], data [\"y_valid\"]\n",
    "    testData, testTarget = data [\"x_test\"], data [\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Creating TensorFlow graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def buildGraph(eta, lambda_, reuseBool):\n",
    "    # Model inputs\n",
    "    with tf.device('/cpu:0'):\n",
    "        with tf.variable_scope('linear_regression', reuse=reuseBool):\n",
    "            with tf.name_scope('placeholders'):\n",
    "                X = tf.placeholder(tf.float32, shape=[None, None], name='Input')\n",
    "                Y = tf.placeholder(tf.float32, shape=[None, None], name='Target')\n",
    "            \n",
    "            # Model variables\n",
    "            with tf.name_scope('parameters'):\n",
    "                W = tf.get_variable('weights', shape=[64, 1], initializer=tf.truncated_normal_initializer(stddev=0.5))\n",
    "                b = tf.get_variable('biases', shape=[1, 1], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "            # Model parameters\n",
    "            with tf.name_scope('hyperparameters'):\n",
    "                eta = tf.get_variable('learning_rate', shape=[], initializer=tf.constant_initializer(eta))\n",
    "                lambda_ = tf.get_variable('L2_regularizer', shape=[], initializer=tf.constant_initializer(lambda_))\n",
    "#                 eta = tf.constant(eta, name='Learning_Rate')\n",
    "#                 lambda_ = tf.constant(lambda_, name='L2_Regularizer')\n",
    "\n",
    "            # Predicted target\n",
    "            with tf.name_scope('prediction'):\n",
    "                Y_hat = tf.matmul(X, W) + b\n",
    "\n",
    "            # Mean squared error\n",
    "            with tf.name_scope('metrics'):\n",
    "                MSE = tf.add(tf.scalar_mul(tf.divide(1.0, tf.cast(tf.shape(X)[0], tf.float32)), \\\n",
    "                                      tf.reduce_sum(tf.square(Y_hat - Y))), \\\n",
    "                             tf.scalar_mul(tf.divide(tf.cast(lambda_, tf.float32), 2.0), \\\n",
    "                                           tf.matmul(tf.transpose(W), W)), \\\n",
    "                             name='MSE')\n",
    "\n",
    "                # Basic accuracy definition (n_correct / n_total)\n",
    "                Y_hat_thresholded = tf.cast(tf.greater_equal(Y_hat, 0.5), tf.float32, name='pred_thresholded')\n",
    "                accuracy = tf.divide(tf.reduce_sum(tf.cast(tf.equal(Y_hat_thresholded, Y), tf.float64)), \\\n",
    "                                     tf.cast(tf.shape(X)[0], tf.float64), \\\n",
    "                                    name='accuracy')\n",
    "\n",
    "        # Basic gradient descent optimizer\n",
    "        optimizer = tf.train.GradientDescentOptimizer(eta).minimize(MSE)\n",
    "        \n",
    "    return W, b, X, Y, Y_hat, MSE, accuracy, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds/Initializes graph for the first time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.ops.variables.Variable at 0x1315f2d90>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x1315f2e10>,\n",
       " <tf.Tensor 'linear_regression/placeholders/Input:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'linear_regression/placeholders/Target:0' shape=(?, ?) dtype=float32>,\n",
       " <tf.Tensor 'linear_regression/prediction/add:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'linear_regression/metrics/MSE:0' shape=(1, 1) dtype=float32>,\n",
       " <tf.Tensor 'linear_regression/metrics/accuracy/truediv:0' shape=() dtype=float64>,\n",
       " <tensorflow.python.framework.ops.Operation at 0x13188a450>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert GRAPH_EXISTS == False\n",
    "buildGraph(1, 1, GRAPH_EXISTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Section 1: Tuning learning rate, $\\eta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 2000\n",
    "def tuneLearningRate(etaList, batchSize=50, lambda_=1):    \n",
    "    # Returns the i-th batch of training data and targets\n",
    "    # Generates a new, reshuffled batch once all previous batches are fed\n",
    "    def getNextTrainingBatch(currentIter):\n",
    "        currentBatchNum = currentIter % (trainData.shape[0] / batchSize)\n",
    "        if currentBatchNum == 0:\n",
    "            np.random.shuffle(randIdx)\n",
    "        # print 'Iteration: %4d, BatchCap: %2d, BatchNum: %2d' % (currentIter, trainData.shape[0] / batchSize, currentBatchNum)\n",
    "        lowerBoundIdx = currentBatchNum * batchSize\n",
    "        upperBoundIdx = (currentBatchNum + 1) * batchSize \n",
    "        return trainData[lowerBoundIdx:upperBoundIdx], trainTarget[lowerBoundIdx:upperBoundIdx]\n",
    "    \n",
    "    # Generate updated plots for training and validation MSE\n",
    "    def plotMSEGraph(MSEList, param):\n",
    "        label = '$\\eta$ = ' + str(param)\n",
    "        label_classification = ['train.', 'valid.']\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        plt.figure(figsize=(8,5), dpi=200)\n",
    "        \n",
    "        for i, MSE in enumerate(MSEList):\n",
    "            plt.plot(range(len(MSE)), MSE, '.', markersize=3, label=label+' '+label_classification[i])\n",
    "        \n",
    "        plt.axis([0, MAX_ITER, 0, np.amax(MSEList)])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # Calculates the ratio between the n-th average epoch MSE and the (n-1)-th average epoch MSE\n",
    "    def ratioAverageEpochMSE(currentValidMSE):\n",
    "        averageN = np.average(currentValidMSE[-(np.arange(epochSize - 1) + 1)])\n",
    "        averageNlessOne = np.average(currentValidMSE[-(np.arange(epochSize - 1) + epochSize)])\n",
    "        return averageN / averageNlessOne\n",
    "    \n",
    "    # Returns True if the average epoch validation MSE is at least 99% of the previous epoch average.\n",
    "    # i.e. Returns True if the average learnings between epoch is less than +1%\n",
    "    # Otherwise, returns False\n",
    "    def shouldStopEarly(currentValidMSE):\n",
    "        if currentValidMSE.shape[0] < 2 * epochSize:\n",
    "            return False\n",
    "        return True if (ratioAverageEpochMSE(currentValidMSE) >= 0.99) else False\n",
    "    \n",
    "    \n",
    "    # Start of function\n",
    "    summaryList = []\n",
    "    randIdx = np.arange(trainData.shape[0])\n",
    "    epochSize = trainData.shape[0] / batchSize\n",
    "    \n",
    "    for eta in etaList:\n",
    "        W, b, X, Y, Y_hat, MSE, accuracy, optimizer = buildGraph(eta, lambda_, reuseBool=True)\n",
    "\n",
    "        with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)) as sess:\n",
    "            writer = tf.summary.FileWriter('/Users/christophertee/Dropbox/University/MASc/Courses/Winter 2017' + \\\n",
    "                                '/ECE521 (Inference Algorithms & Machine Learning)/Assignment 1/Logs/Train', \\\n",
    "                                graph=sess.graph)\n",
    "            tf.global_variables_initializer().run()\n",
    "\n",
    "            # Creates blank training and validation MSE arrays for the Session\n",
    "            currentTrainMSE = np.array([])[:, np.newaxis]\n",
    "            currentValidMSE = np.array([])[:, np.newaxis]\n",
    "    \n",
    "            # Runs update\n",
    "            currentIter = 0\n",
    "            while currentIter <= MAX_ITER:\n",
    "                inputData, inputTarget = getNextTrainingBatch(currentIter)\n",
    "                \n",
    "                _, trainError = sess.run([optimizer, MSE], feed_dict={X: inputData, Y: inputTarget})\n",
    "                validError = sess.run([MSE], feed_dict={X: validData, Y: validTarget})\n",
    "\n",
    "                currentTrainMSE = np.append(currentTrainMSE, trainError)\n",
    "                currentValidMSE = np.append(currentValidMSE, validError)\n",
    "                \n",
    "                # Update graph of training and validation MSE arrays\n",
    "                if (currentIter < 3) or (currentIter % 500 == 0):\n",
    "                    pass\n",
    "                    # writer.add_summary(trainSummary, currentIter)\n",
    "                # plotMSEGraph([currentTrainMSE, currentValidMSE], eta)\n",
    "                \n",
    "                # At every epoch, check for early stopping possibilty. If so, breaks from while loop\n",
    "                if currentIter % epochSize == 0:\n",
    "                    if shouldStopEarly(currentValidMSE):\n",
    "                        writer.close()\n",
    "                        break\n",
    "                \n",
    "                currentIter += 1\n",
    "            \n",
    "        # Save session results as dictionary and appends to MSEsummaryList\n",
    "        summaryList.append(\n",
    "            {\n",
    "                'eta': eta,\n",
    "                'B': batchSize,\n",
    "                'lambda': lambda_,\n",
    "                'numIter': currentIter + 1,\n",
    "                'epoch': float(currentIter + 1) / (trainData.shape[0] / batchSize),\n",
    "                'trainMSE': currentTrainMSE,\n",
    "                'validMSE': currentValidMSE,\n",
    "            }\n",
    "        )\n",
    "            \n",
    "    return summaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta: 0.001, numIter: 1835, validMSE: 0.293\n",
      "eta: 0.010, numIter: 365, validMSE: 0.180\n",
      "eta: 0.100, numIter: 71, validMSE: 0.182\n"
     ]
    }
   ],
   "source": [
    "etaList = [0.001, 0.01, 0.1]\n",
    "tunedEtaSummary = tuneLearningRate(etaList)\n",
    "\n",
    "# Output summary table\n",
    "for summary in tunedEtaSummary:\n",
    "    print 'eta: %.3f, numIter: %d, validMSE: %.3f' % (summary['eta'], summary['numIter'], summary['validMSE'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Produce interactive graph for best learning rate, $\\eta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~rsolitude/26.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def etaIGraph(tunedEtaSummary):\n",
    "    # Create plot for each summary\n",
    "    traceList = []\n",
    "    for summary in tunedEtaSummary:\n",
    "        traceList.append(\n",
    "            go.Scatter(\n",
    "                x = range(summary['numIter'] + 1),\n",
    "                y = summary['trainMSE'],\n",
    "                name = '$\\\\eta = ' + str(summary['eta']) + '$'\n",
    "            )\n",
    "        )\n",
    "    data = go.Data(traceList)\n",
    "    \n",
    "    # Create figure layout\n",
    "    layout = go.Layout(\n",
    "        title = '$\\\\textit{Training performance for various learning rates, } \\\\eta$',\n",
    "        xaxis = {'title': 'Number of Updates'},\n",
    "        yaxis = {'title': 'Training MSE'},\n",
    "    )\n",
    "\n",
    "    figure = go.Figure(data=data, layout=layout)\n",
    "    return py.iplot(figure, filename='A1Q2.1_bestEtaGraph')\n",
    "fig2_1 = etaIGraph(tunedEtaSummary)\n",
    "fig2_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Section 2: Tuning mini-batch size, $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 6000\n",
    "def tuneBatchSize(etaList, batchSizeList, lambda_=1):\n",
    "    # Returns the i-th batch of training data and targets\n",
    "    # Generates a new, reshuffled batch once all previous batches are fed\n",
    "    def getNextTrainingBatch(currentIter):\n",
    "        currentBatchNum = currentIter % (trainData.shape[0] / batchSize)\n",
    "        if currentBatchNum == 0:\n",
    "            np.random.shuffle(randIdx)\n",
    "        # print currentBatchNum + 1\n",
    "        lowerBoundIdx = currentBatchNum * batchSize\n",
    "        upperBoundIdx = (currentBatchNum + 1) * batchSize \n",
    "        return trainData[lowerBoundIdx:upperBoundIdx], trainTarget[lowerBoundIdx:upperBoundIdx]\n",
    "    \n",
    "    # Generate updated plots for training and validation MSE\n",
    "    def plotMSEGraph(MSEList, param):\n",
    "        label = '$B$ = ' + str(param[0]) + ', $\\eta$: ' + str(param[1])\n",
    "        label_classification = ['train.', 'valid.']\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        plt.figure(figsize=(8,5), dpi=200)\n",
    "        \n",
    "        for i, MSE in enumerate(MSEList):\n",
    "            plt.plot(range(len(MSE)), MSE, '.', markersize=3, label=label+'\\n'+label_classification[i])\n",
    "        \n",
    "        plt.axis([0, MAX_ITER, 0, np.amax(MSEList)])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # Calculates the ratio between the n-th average epoch MSE and the (n-1)-th average epoch MSE\n",
    "    def ratioAverageEpochMSE(currentValidMSE):\n",
    "        averageN = np.average(currentValidMSE[-(np.arange(epochSize - 1) + 1)])\n",
    "        averageNlessOne = np.average(currentValidMSE[-(np.arange(epochSize - 1) + epochSize)])\n",
    "        return averageN / averageNlessOne\n",
    "    \n",
    "    # Returns True if the average epoch validation MSE is at least 99% of the previous epoch average.\n",
    "    # i.e. Returns True if the average learnings between epoch is less than +1%\n",
    "    # Otherwise, returns False\n",
    "    def shouldStopEarly(currentValidMSE):\n",
    "        if currentValidMSE.shape[0] < 2 * epochSize:\n",
    "            return False\n",
    "        return True if (ratioAverageEpochMSE(currentValidMSE) >= 0.99) else False\n",
    "    \n",
    "    summaryList = []\n",
    "    randIdx = np.arange(trainData.shape[0])\n",
    "    \n",
    "    for batchSize in batchSizeList:\n",
    "        epochSize = trainData.shape[0] / batchSize\n",
    "        batchSummary = []\n",
    "        for eta in etaList:\n",
    "            W, b, X, Y, Y_hat, MSE, accuracy, optimizer = buildGraph(eta, lambda_)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                tf.global_variables_initializer().run()\n",
    "\n",
    "                # Creates blank training and validation MSE arrays for the Session\n",
    "                currentTrainMSE = np.array([])[:, np.newaxis]\n",
    "                currentValidMSE = np.array([])[:, np.newaxis]\n",
    "\n",
    "                # Runs update\n",
    "                currentIter = 0\n",
    "                while currentIter <= MAX_ITER:\n",
    "                    inputData, inputTarget = getNextTrainingBatch(currentIter)\n",
    "\n",
    "                    _, trainError = sess.run([optimizer, MSE], feed_dict={X: inputData, Y: inputTarget})\n",
    "                    validError = sess.run([MSE], feed_dict={X: validData, Y: validTarget})\n",
    "\n",
    "                    currentTrainMSE = np.append(currentTrainMSE, trainError)\n",
    "                    currentValidMSE = np.append(currentValidMSE, validError)\n",
    "\n",
    "                    # Update graph of training and validation MSE arrays\n",
    "                    if (currentIter < 3) or (currentIter % 500 == 0):\n",
    "                        pass\n",
    "                        # plotMSEGraph([currentTrainMSE, currentValidMSE], [batchSize, eta])\n",
    "\n",
    "                    # At every epoch, check for early stopping possibilty. If so, breaks from while loop\n",
    "                    if currentIter % epochSize == 0:\n",
    "                        if shouldStopEarly(currentValidMSE):\n",
    "                            break\n",
    "\n",
    "                    currentIter += 1\n",
    "\n",
    "            # Save session results as dictionary and appends to MSEsummaryList\n",
    "            batchSummary.append(\n",
    "                {\n",
    "                    'eta': eta,\n",
    "                    'B': batchSize,\n",
    "                    'lambda': lambda_,\n",
    "                    'numIter': currentIter + 1,\n",
    "                    'epoch': float(currentIter + 1) / (trainData.shape[0] / batchSize),\n",
    "                    'trainMSE': currentTrainMSE,\n",
    "                    'validMSE': currentValidMSE,\n",
    "                }\n",
    "            )\n",
    "        summaryList.append(batchSummary)\n",
    "            \n",
    "    return summaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B:    10, eta: 0.001, numIter:  2801, validMSE: 0.228\n",
      "B:    10, eta: 0.010, numIter:   491, validMSE: 0.213\n",
      "B:    10, eta: 0.100, numIter:   211, validMSE: 0.231\n",
      "B:    50, eta: 0.001, numIter:  1877, validMSE: 0.325\n",
      "B:    50, eta: 0.010, numIter:   323, validMSE: 0.218\n",
      "B:    50, eta: 0.100, numIter:    57, validMSE: 0.217\n",
      "B:   100, eta: 0.001, numIter:   806, validMSE: 1.002\n",
      "B:   100, eta: 0.010, numIter:   260, validMSE: 0.228\n",
      "B:   100, eta: 0.100, numIter:    43, validMSE: 0.215\n",
      "B:   700, eta: 0.001, numIter:  6002, validMSE: 0.213\n",
      "B:   700, eta: 0.010, numIter:  6002, validMSE: 0.213\n",
      "B:   700, eta: 0.100, numIter:  6002, validMSE: 0.213\n"
     ]
    }
   ],
   "source": [
    "etaList = [0.001, 0.01, 0.1]\n",
    "batchSizeList = [10, 50, 100, 700]\n",
    "tunedBatchSizeSummary = tuneBatchSize(etaList, batchSizeList)\n",
    "\n",
    "# Output summary table:\n",
    "for batchSummary in tunedBatchSizeSummary:\n",
    "    for summary in batchSummary:\n",
    "        print 'B: %5d, eta: %5.3f, numIter: %5d, validMSE: %3.3f' % \\\n",
    "            (summary['B'], summary['eta'], summary['numIter'], summary['validMSE'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Produce interactive graph for each mini-batch size, $B$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def batchSizeIGraphSubplot(tunedBatchSizeSummary):\n",
    "    \n",
    "    # Define subplot title\n",
    "    subplotTitle = []\n",
    "    for batchSummary in tunedBatchSizeSummary:\n",
    "        subplotTitle.append('Batch Size, B  = ' + str(batchSummary[0]['B']))\n",
    "    \n",
    "    # Define subplot figure\n",
    "    figure = tools.make_subplots(rows=4, cols=1, subplot_titles=(subplotTitle))\n",
    "    \n",
    "    # Define color list\n",
    "    colorList = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "    \n",
    "    # Create plot for each summary\n",
    "    for i, batchSummary in enumerate(tunedBatchSizeSummary):\n",
    "        traceList = []\n",
    "        for j, summary in enumerate(batchSummary):\n",
    "            trace = go.Scatter(\n",
    "                x = range(summary['numIter'] + 1),\n",
    "                y = summary['trainMSE'],\n",
    "                marker = {'color': colorList[j]},\n",
    "                name = '$B=' + str(summary['B']) + ', \\\\eta=' + str(summary['eta']) + '$'\n",
    "            )\n",
    "            figure.append_trace(trace, i + 1, 1)\n",
    "        figure['layout']['xaxis'+str(i+1)].update(title='Number of Updates')\n",
    "        figure['layout']['yaxis'+str(i+1)].update(title='Training MSE')\n",
    "\n",
    "    # Create figure layout\n",
    "    figure['layout'].update(\n",
    "        height = 1800,\n",
    "        title = '$\\\\textit{Model training performance for various batch size, } B' + \\\n",
    "                '\\\\textit{, and learning rate, } \\\\eta$',\n",
    "        showlegend = False\n",
    "    )\n",
    "\n",
    "    return py.iplot(figure, filename='A1Q2.2_batch_size_subplot2x2')\n",
    "fig2_2_visual = batchSizeIGraphSubplot(tunedBatchSizeSummary)\n",
    "fig2_2_visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Section 3: Tuning $\\ell_2$ regularizer, $\\lambda$, using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 2000\n",
    "def tuneLambda(lambdaList, eta=0.1, batchSize=50):\n",
    "    # Returns the i-th batch of training data and targets\n",
    "    # Generates a new, reshuffled batch once all previous batches are fed\n",
    "    def getNextTrainingBatch(currentIter):\n",
    "        currentBatchNum = currentIter % (trainData.shape[0] / batchSize)\n",
    "        if currentBatchNum == 0:\n",
    "            np.random.shuffle(randIdx)\n",
    "        lowerBoundIdx = currentBatchNum * batchSize\n",
    "        upperBoundIdx = (currentBatchNum + 1) * batchSize \n",
    "        return trainData[lowerBoundIdx:upperBoundIdx], trainTarget[lowerBoundIdx:upperBoundIdx]\n",
    "    \n",
    "    # Generate updated plots for training and validation MSE\n",
    "    def plotMSEGraph(MSEList, param):\n",
    "        label = '$\\lambda$ = ' + str(param)\n",
    "        label_classification = ['train.', 'valid.']\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        plt.figure(figsize=(8,5), dpi=200)\n",
    "        \n",
    "        for i, MSE in enumerate(MSEList):\n",
    "            plt.plot(range(len(MSE)), MSE, '-', label=label+' '+label_classification[i])\n",
    "        \n",
    "        plt.axis([0, MAX_ITER, 0, np.amax(MSEList)])\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # Calculates the ratio between the n-th average epoch MSE and the (n-1)-th average epoch MSE\n",
    "    def ratioAverageEpochMSE(currentValidMSE):\n",
    "        averageN = np.average(currentValidMSE[-(np.arange(epochSize - 1) + 1)])\n",
    "        averageNlessOne = np.average(currentValidMSE[-(np.arange(epochSize - 1) + epochSize)])\n",
    "        return averageN / averageNlessOne\n",
    "    \n",
    "    # Returns True if the average epoch validation MSE is at least 99% of the previous epoch average.\n",
    "    # i.e. Returns True if the average learnings between epoch is less than +1%\n",
    "    # Otherwise, returns False\n",
    "    def shouldStopEarly(currentValidMSE):\n",
    "        if currentValidMSE.shape[0] < 2 * epochSize:\n",
    "            return False\n",
    "        return True if (ratioAverageEpochMSE(currentValidMSE) >= 0.99) else False\n",
    "    \n",
    "    summaryList = []\n",
    "    randIdx = np.arange(trainData.shape[0])\n",
    "    epochSize = trainData.shape[0] / batchSize\n",
    "    \n",
    "    for lambda_ in lambdaList:\n",
    "        W, b, X, Y, Y_hat, MSE, accuracy, optimizer = buildGraph(eta, lambda_)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            tf.global_variables_initializer().run()\n",
    "            \n",
    "            # Creates blank training and validation MSE arrays for the Session\n",
    "            currentTrainMSE = np.array([])[:, np.newaxis]\n",
    "            currentValidMSE = np.array([])[:, np.newaxis]\n",
    "            \n",
    "            # Runs update\n",
    "            currentIter = 0\n",
    "            while currentIter <= MAX_ITER:\n",
    "                inputData, inputTarget = getNextTrainingBatch(currentIter)\n",
    "                \n",
    "                _, trainError = sess.run([optimizer, MSE], feed_dict={X: inputData, Y: inputTarget})\n",
    "                validError = sess.run([MSE], feed_dict={X: validData, Y: validTarget})\n",
    "\n",
    "                currentTrainMSE = np.append(currentTrainMSE, trainError)\n",
    "                currentValidMSE = np.append(currentValidMSE, validError)\n",
    "                \n",
    "                # Update graph of training and validation MSE arrays\n",
    "                if (currentIter < 3) or (currentIter % 500 == 0):\n",
    "                    plotMSEGraph([currentTrainMSE, currentValidMSE], lambda_)\n",
    "                \n",
    "                # At every epoch, check for early stopping possibilty. If so, breaks from while loop\n",
    "                if currentIter % epochSize == 0:\n",
    "                    if shouldStopEarly(currentValidMSE):\n",
    "                        break\n",
    "                \n",
    "                currentIter += 1\n",
    "            \n",
    "            # Compute validation and test accuracy\n",
    "            validAccuracy = sess.run(accuracy, feed_dict={X: validData, Y: validTarget})\n",
    "            testAccuracy = sess.run(accuracy, feed_dict={X: testData, Y: testTarget})\n",
    "            \n",
    "        # Save session results as dictionary and appends to MSEsummaryList\n",
    "        summaryList.append(\n",
    "            {\n",
    "                'eta': eta,\n",
    "                'B': batchSize,\n",
    "                'lambda': lambda_,\n",
    "                'numIter': currentIter + 1,\n",
    "                'epoch': float(currentIter + 1) / (trainData.shape[0] / batchSize),\n",
    "                'trainMSE': currentTrainMSE,\n",
    "                'validMSE': currentValidMSE,\n",
    "                'validAccuracy': validAccuracy,\n",
    "                'testAccuracy': testAccuracy\n",
    "            }\n",
    "        )\n",
    "            \n",
    "    return summaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lambdaList = [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "tunedLambdaSummary = tuneLambda(lambdaList)\n",
    "\n",
    "# Output summary table\n",
    "for summary in tunedLambdaSummary:\n",
    "    print 'lambda: %5.4f, numIter: %5d, validMSE: %5.3f, validAcc: %3.3f, testAcc: %3.3f' % \\\n",
    "        (summary['lambda'], summary['numIter'], summary['validMSE'][-1], summary['validAccuracy'], summary['testAccuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Produce interactive graph for validation set accuracy vs $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lambdaIGraph(tunedLambdaSummary):\n",
    "    # Create plot for each summary\n",
    "    trace1 = go.Scatter(\n",
    "        x = [np.log10(summary['lambda'] + 1e-5) for summary in tunedLambdaSummary],\n",
    "        y = [summary['validAccuracy'] for summary in tunedLambdaSummary],\n",
    "        name = 'Validation set accuracy'\n",
    "    )\n",
    "    \n",
    "    trace2 = go.Scatter(\n",
    "        x = [np.log10(summary['lambda'] + 1e-5) for summary in tunedLambdaSummary],\n",
    "        y = [summary['testAccuracy'] for summary in tunedLambdaSummary],\n",
    "        name = 'Test set accuracy'\n",
    "    )\n",
    "    \n",
    "    data = go.Data([trace1, trace2])\n",
    "    \n",
    "    # Create figure layout\n",
    "    layout = go.Layout(\n",
    "        title = '$\\\\textit{Validation and Test set accuracy vs. } \\\\lambda$',\n",
    "        xaxis = {'title': '$\\\\log_{10}(\\\\lambda)$'},\n",
    "        yaxis = {'title': 'Model Accuracy'},\n",
    "        annotations = [\n",
    "            dict(\n",
    "                text = '$\\\\textit{Used to represent } \\\\log_{10}(\\\\lambda=0)$',\n",
    "                x = -5,\n",
    "                y = 0.90,\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    figure = go.Figure(data=data, layout=layout)\n",
    "    return py.iplot(figure, filename='A1Q2.3_accuracyVsLambda')\n",
    "fig2_3 = lambdaIGraph(tunedLambdaSummary)\n",
    "fig2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
